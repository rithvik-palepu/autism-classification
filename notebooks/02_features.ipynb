{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T02:28:23.217788Z",
     "start_time": "2025-11-05T02:28:21.668984Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved (884, 19900) (884,) (884,) (884,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def vectorize_connectome(matrix):\n",
    "    triu_idx = np.triu_indices_from(matrix, k=1)\n",
    "    return matrix[triu_idx]\n",
    "\n",
    "connectome_dir = Path(\"../data/interim/connectomes_cc200\")\n",
    "pheno_csv = \"../data/raw/Phenotypic_V1_0b_preprocessed1.csv\"\n",
    "\n",
    "# Read pheno and robustly locate the FILE_ID column (handles extra spaces/case)\n",
    "pheno = pd.read_csv(pheno_csv)\n",
    "\n",
    "# normalize column names (strip whitespace)\n",
    "pheno.columns = pheno.columns.str.strip()\n",
    "\n",
    "# try to find a column that corresponds to FILE_ID, tolerant to spaces/underscores/case\n",
    "norm_map = {col: col.strip().upper().replace(\" \", \"_\") for col in pheno.columns}\n",
    "file_id_col = None\n",
    "for col, norm in norm_map.items():\n",
    "    if norm == \"FILE_ID\":\n",
    "        file_id_col = col\n",
    "        break\n",
    "\n",
    "if file_id_col is None:\n",
    "    # maybe the index already contains FILE_ID\n",
    "    if pheno.index.name and pheno.index.name.strip().upper().replace(\" \", \"_\") == \"FILE_ID\":\n",
    "        # ensure index values are strings and stripped\n",
    "        pheno.index = pheno.index.astype(str).str.strip()\n",
    "    else:\n",
    "        raise KeyError(f\"FILE_ID column not found in pheno CSV. Available columns: {list(pheno.columns)}\")\n",
    "else:\n",
    "    # ensure values are strings and stripped, then set index\n",
    "    pheno[file_id_col] = pheno[file_id_col].astype(str).str.strip()\n",
    "    pheno = pheno.set_index(file_id_col)\n",
    "\n",
    "X, y, subjects = [], [], []\n",
    "\n",
    "for f in sorted(connectome_dir.glob(\"*.npy\")):\n",
    "    subj_id = f.stem.split(\"_rois\")[0]\n",
    "    if subj_id not in pheno.index:\n",
    "        # subject not found in phenotypic table\n",
    "        continue\n",
    "    # get row as a Series\n",
    "    row = pheno.loc[subj_id]\n",
    "    mat = np.load(f)\n",
    "    X.append(vectorize_connectome(mat))\n",
    "    # row may be a Series; ensure DX_GROUP is retrieved correctly\n",
    "    dx = int(row[\"DX_GROUP\"]) if \"DX_GROUP\" in row.index else int(row[\"DX_GROUP\"].values[0])\n",
    "    y.append(1 if dx == 1 else 0)\n",
    "    subjects.append(subj_id)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "subjects = np.array(subjects)\n",
    "# pheno is indexed by FILE_ID now, so loc with subjects will work\n",
    "sites = pheno.loc[subjects, \"SITE_ID\"].values\n",
    "\n",
    "np.save(\"../data/processed/X.npy\", X)\n",
    "np.save(\"../data/processed/y.npy\", y)\n",
    "np.save(\"../data/processed/subjects.npy\", subjects)\n",
    "np.save(\"../data/processed/sites.npy\", sites)\n",
    "print(\"Saved\", X.shape, y.shape, subjects.shape, sites.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
